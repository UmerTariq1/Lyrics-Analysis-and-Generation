{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2558, 9)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_FILEPATH = \"data/data_clean_en_3.csv\"\n",
    "df = pd.read_csv(CSV_FILEPATH)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prompt=\"\"\"You are a English song Lyricist. Famous singers come to you with descriptions of the kind of song they want you to write.\n",
    "They also give you some examples of the song lyrics based on the description. \n",
    "Output only the lyrics of the song that you should write. do not output anything else.\n",
    "The avg number of words in lyrics should be around 500-600 and it should have some chorus and verses.\n",
    "\n",
    "Format of the examples is:\n",
    "-- Description: <description of the song>\n",
    "-- Lyrics : <lyrics of the song>\n",
    "\n",
    "----------------------------------- EXAMPLES START -----------------------------------\n",
    "-- Description 1: ```{desc_1}``` \n",
    "-- Lyrics 1: ```{lyrics_1}``` \n",
    "\n",
    "-- Description 2: ```{desc_2}``` \n",
    "-- Lyrics 2: ```{lyrics_2}``` \n",
    "\n",
    "-- Description 3: ```{desc_3}``` \n",
    "-- Lyrics 3: ```{lyrics_3}``` \n",
    "\n",
    "-- Description 4: ```{desc_4}``` \n",
    "-- Lyrics 4: ```{lyrics_4}``` \n",
    "\n",
    "-- Description 5: ```{desc_5}``` \n",
    "-- Lyrics 5: ```{lyrics_5}``` \n",
    "\n",
    "----------------------------------- EXAMPLES END -----------------------------------\n",
    "\n",
    "Note that the avg number of words in lyrics should be around 500-600 and it should have some repeating chorus and verses. \n",
    "\n",
    "-- Description: ```{desc_user}``` \n",
    "\n",
    "-- Lyrics : \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title QA_Pipeline_TfIdf { form-width: \"20%\" }\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "class QA_Pipeline_TfIdf:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass        \n",
    "\n",
    "    def normalizeData(self,data,isNormalizeAgainstMax=False):\n",
    "        if sum(data)==0:\n",
    "            return data\n",
    "        if isNormalizeAgainstMax:\n",
    "          return [float(i)/max(data) for i in data]  # to normalize against max\n",
    "        else:\n",
    "          return [float(i)/sum(data) for i in data]  # to normalize to make sum = 1\n",
    "        \n",
    "\n",
    "    def create_tfidf_features(self,data, max_features=5000, max_df=0.85, min_df=2):\n",
    "        \"\"\" Creates a tf-idf matrix for the `data` using sklearn. \"\"\"\n",
    "        tfidf_vectorizor = TfidfVectorizer(decode_error='replace', strip_accents='unicode', analyzer='word',\n",
    "                                        stop_words='english', ngram_range=(1, 1), max_features=max_features,\n",
    "                                        norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    "                                        max_df=max_df, min_df=min_df)\n",
    "        X = tfidf_vectorizor.fit_transform(data)\n",
    "        print('tfidf matrix successfully created.')\n",
    "        return X, tfidf_vectorizor\n",
    "\n",
    "    def calculate_similarity( self,query, top_k=20):\n",
    "        \"\"\" Vectorizes the `query` via `vectorizer` and calculates the cosine similarity of\n",
    "        the `query` and `allDocuments` (all the documents) and returns the `top_k` similar documents.\"\"\"\n",
    "        \n",
    "        # Vectorize the query to the same length as documents\n",
    "        query_vec = self.vectorizer.transform(query)\n",
    "        # Compute the cosine similarity between query_vec and all the documents\n",
    "        cosine_similarities = cosine_similarity(self.tfidfTransformed_docs,query_vec).flatten()\n",
    "\n",
    "        # Sort the similar documents from the most similar to less similar and return the indices\n",
    "        most_similar_doc_indices = np.argsort(cosine_similarities, axis=0)[:-top_k-1:-1]\n",
    "\n",
    "        # Sort the similar documents from the most similar to less similar and return the scores\n",
    "        cosine_similarities = np.sort(cosine_similarities)[:-top_k-1:-1]\n",
    "\n",
    "        # #normalize scores\n",
    "        cosine_similarities = self.normalizeData(cosine_similarities,isNormalizeAgainstMax=True)\n",
    "        return most_similar_doc_indices, cosine_similarities\n",
    "\n",
    "    def RunTfIdf(self,question,top_n=20, getDocuments=False,data=None):\n",
    "        '''\n",
    "        given a question find the top_n most similar documents.\n",
    "        if document text is also needed then pass getDocuments=True and pass the data which was originally passed to createTfIdfTable\n",
    "        '''\n",
    "        top_idx,cosine_similarities = self.calculate_similarity( [question],top_k=top_n)\n",
    "        \n",
    "        if getDocuments:\n",
    "            if data==None:\n",
    "                sys.exit('data to be returned but no data provided. data is n')\n",
    "            retData = [data[i] for i in top_idx]\n",
    "            return top_idx,cosine_similarities,retData \n",
    "        else:\n",
    "            return top_idx,cosine_similarities\n",
    "\n",
    "    def createTfIdfTable(self,data,maxFeatures=10000):\n",
    "        self.tfidfTransformed_docs,self.vectorizer = self.create_tfidf_features( data  ,max_features=maxFeatures)\n",
    "        # features = vectorizer.get_feature_names()\n",
    "\n",
    "    def get_nearest_songs(self, data_df, text, top_n=5):\n",
    "        '''\n",
    "        given a string text, fine the nearest songs descriptions from the data\n",
    "        return a list of descriptions and lyrics\n",
    "        '''\n",
    "\n",
    "        desc_data  = data_df['description'].tolist()\n",
    "\n",
    "\n",
    "        self.createTfIdfTable(desc_data,maxFeatures=10000)\n",
    "\n",
    "        top_idx,cosine_similarities,retData  = self.RunTfIdf(text, top_n=top_n, getDocuments=True, data=desc_data)\n",
    "\n",
    "        # get the descriptions of top_idx from df\n",
    "        desc = []\n",
    "        lyrics = []\n",
    "        titles = []\n",
    "        ids = []\n",
    "\n",
    "        df_titles = data_df['title'].tolist()\n",
    "        df_ids = data_df['id'].tolist()\n",
    "        df_desc = data_df['description'].tolist()\n",
    "        df_lyrics = data_df['lyrics_clean_with_newline'].tolist()\n",
    "\n",
    "\n",
    "        for i in top_idx:\n",
    "            desc.append(df_desc[i])\n",
    "            lyrics.append(df_lyrics[i])\n",
    "            titles.append(df_titles[i])\n",
    "            ids.append(df_ids[i])\n",
    "\n",
    "        return ids, titles, desc, lyrics\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "eminem_df = df[df['artist']=='Eminem']\n",
    "eminem_desc = eminem_df['description'].tolist()\n",
    "eminem_lyrics = eminem_df['lyrics_clean_with_newline'].tolist()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = QA_Pipeline_TfIdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf matrix successfully created.\n"
     ]
    }
   ],
   "source": [
    "# add the question to the pre_prompt\n",
    "text = \"You are a liar. you lied to me. you lied to my kid. you are dead to me. I will never forget what you did. I will never forgive you.\"\n",
    "ids, titles, desc, lyrics = tfidf.get_nearest_songs(eminem_df, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"desc_1\"] = desc[0]\n",
    "params[\"desc_2\"] = desc[1]\n",
    "params[\"desc_3\"] = desc[2]\n",
    "params[\"desc_4\"] = desc[3]\n",
    "params[\"desc_5\"] = desc[4]\n",
    "params[\"lyrics_1\"] = lyrics[0]\n",
    "params[\"lyrics_2\"] = lyrics[1]\n",
    "params[\"lyrics_3\"] = lyrics[2]\n",
    "params[\"lyrics_4\"] = lyrics[3]\n",
    "params[\"lyrics_5\"] = lyrics[4]\n",
    "\n",
    "params[\"desc_user\"] = text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = pre_prompt\n",
    "input_variables = [desc_1, lyrics_1, desc_2, lyrics_2, desc_3, lyrics_3, desc_4, lyrics_4, desc_5, lyrics_5, desc_user] # parameters. for tempalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title generate_lyrics function\n",
    "def generate_lyrics(desc_user, data_df, prompt_template, input_variables, specific_artist=None ):\n",
    "    '''\n",
    "        Given the user query/descipriton of the lyrics, return the lyrics of the song\n",
    "    '''\n",
    "\n",
    "\n",
    "    template = prompt_template\n",
    "    input_variables = input_variables\n",
    "\n",
    "\n",
    "\n",
    "    if specific_artist is None:\n",
    "        sub_df = data_df\n",
    "\n",
    "    else:\n",
    "        # repalce \"Format of the examples is:\" with \"the Lyrics should be in the style of <artist_name>.\" + \"\\n Format of the examples is:\"\n",
    "        temp = \"Format of the examples is:\"\n",
    "        template = template.replace(temp, \"the Lyrics should be in the style of \" + specific_artist + \".\\n\" + temp)\n",
    "\n",
    "        try:\n",
    "            sub_df = data_df[data_df['artist']==specific_artist]\n",
    "            # if this artist has less then 5 entries then get the whole df\n",
    "            if sub_df.shape[0] < 5:\n",
    "                print(\"This artist has less than 5 songs. taking the whole data\")\n",
    "                sub_df = data_df \n",
    "        except:\n",
    "            print(\"Artist wasnt found. taking the whole data\")\n",
    "            sub_df = data_df\n",
    "    \n",
    "\n",
    "    llm_chain = initialize_model(template, input_variables)\n",
    "\n",
    "\n",
    "    tfidf = QA_Pipeline_TfIdf()\n",
    "\n",
    "    ids, titles, desc, lyrics = tfidf.get_nearest_songs(sub_df, desc_user)\n",
    "\n",
    "    params = {}\n",
    "    params[\"desc_1\"] = desc[0]\n",
    "    params[\"desc_2\"] = desc[1]\n",
    "    params[\"desc_3\"] = desc[2]\n",
    "    params[\"desc_4\"] = desc[3]\n",
    "    params[\"desc_5\"] = desc[4]\n",
    "    params[\"lyrics_1\"] = lyrics[0]\n",
    "    params[\"lyrics_2\"] = lyrics[1]\n",
    "    params[\"lyrics_3\"] = lyrics[2]\n",
    "    params[\"lyrics_4\"] = lyrics[3]\n",
    "    params[\"lyrics_5\"] = lyrics[4]\n",
    "\n",
    "    params[\"desc_user\"] = desc_user\n",
    "\n",
    "    \n",
    "    model_output = llm_chain.run(params)\n",
    "\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taylor_df = df[df['artist']=='Taylor Swift']\n",
    "\n",
    "desc_user = \"You are a liar. you lied to me. you lied to my kid. you are dead to me. I will never forget what you did. I will never forgive you.\"\n",
    "\n",
    "tfidf = QA_Pipeline_TfIdf()\n",
    "\n",
    "ids, titles, desc, lyrics = tfidf.get_nearest_songs(taylor_df, desc_user)\n",
    "\n",
    "params = {}\n",
    "params[\"desc_1\"] = desc[0]\n",
    "params[\"desc_2\"] = desc[1]\n",
    "params[\"desc_3\"] = desc[2]\n",
    "params[\"desc_4\"] = desc[3]\n",
    "params[\"desc_5\"] = desc[4]\n",
    "params[\"lyrics_1\"] = lyrics[0]\n",
    "params[\"lyrics_2\"] = lyrics[1]\n",
    "params[\"lyrics_3\"] = lyrics[2]\n",
    "params[\"lyrics_4\"] = lyrics[3]\n",
    "params[\"lyrics_5\"] = lyrics[4]\n",
    "\n",
    "params[\"desc_user\"] = desc_user\n",
    "\n",
    "\n",
    "model_output = llm_chain.run(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf matrix successfully created.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of words in pre prompt\n",
    "len(pre_prompt.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add each desc and lyrics to the pre_prompt\n",
    "for i in range(len(ids)):\n",
    "    pre_prompt += \"-- Description: \" + desc[i] + \"\\n\"\n",
    "    pre_prompt += \"-- Lyrics: \" + lyrics[i] + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5034"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of words in pre prompt\n",
    "len(pre_prompt.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The song \"Rock Bottom\" explores the struggles and hardships of a person who is living in poverty and facing constant financial difficulties. The lyrics depict a life filled with empty promises, broken dreams, and a constant feeling of hopelessness. The protagonist is trapped in a cycle of dead-end jobs with low pay, constantly being hired and fired, and living in a house without basic necessities. The song also touches upon the desperation and frustration that arises from wanting a better life but feeling unable to attain it. The lyrics convey a sense of anger and sadness, as the protagonist contemplates the idea of resorting to criminal activities to survive. Overall, \"Rock Bottom\" portrays the emotional turmoil and despair that can arise from living in poverty and the desire for a better life.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the question to the pre_prompt\n",
    "pre_prompt += \"\\n\\n ------------------------------ EXAMPLES END ------------------------------  \\n Now the user's actual query. Note that the avg number of words in lyrics should be around 500-600 and it should have some chorus and verses. \\n \"\n",
    "\n",
    "pre_prompt += \"-- Description: \" + text + \"\\n\"\n",
    "pre_prompt += \"-- Lyrics: \" + \" \" + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5098"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of words in pre prompt\n",
    "len(pre_prompt.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String saved to temp_preprompt.txt\n"
     ]
    }
   ],
   "source": [
    "# save text to txt file  pre_prompt\n",
    "output_filepath = \"temp_preprompt.txt\"\n",
    "\n",
    "# 3. Open the file in write mode and save the string\n",
    "try:\n",
    "    with open(output_filepath, 'w') as file:\n",
    "        file.write(pre_prompt)\n",
    "    print(\"String saved to\", output_filepath)\n",
    "except IOError as e:\n",
    "    print(\"An error occurred while saving the file:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['artist']=='Eric Clapton'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
